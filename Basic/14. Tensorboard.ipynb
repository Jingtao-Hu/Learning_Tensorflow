{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sunqu\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICE\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight(shape, name):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def bias(shape, name):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial, name=name)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-7c4a69256204>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\sunqu\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\sunqu\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\sunqu\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\sunqu\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST\\t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\sunqu\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1=5;H1=5;C1=32\n",
    "W2=5;H2=5;C2=64\n",
    "C3=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('input_data'):\n",
    "    x = tf.placeholder(tf.float32, [None,28*28])\n",
    "    y_gt = tf.placeholder(tf.float32, [None,10])\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    tf.summary.image('input', x_image, max_outputs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name histogram of W1 is illegal; using histogram_of_W1 instead.\n",
      "INFO:tensorflow:Summary name histogram of b1 is illegal; using histogram_of_b1 instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('hidden1'):\n",
    "    W_conv1 = weight([W1,H1,1,C1], name='weights')\n",
    "    b_conv1 = bias([C1], name='bias')\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "    tf.summary.histogram('histogram of W1', W_conv1)\n",
    "    tf.summary.histogram('histogram of b1', b_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name histogram of W2 is illegal; using histogram_of_W2 instead.\n",
      "INFO:tensorflow:Summary name histogram of b2 is illegal; using histogram_of_b2 instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('hidden2'):\n",
    "    W_conv2 = weight([W2,H2,C1,C2], name='weights')\n",
    "    b_conv2 = weight([C2], name='bias')\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    tf.summary.histogram('histogram of W2', W_conv2)\n",
    "    tf.summary.histogram('histogram of b2', b_conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name hsitogram of W_fc is illegal; using hsitogram_of_W_fc instead.\n",
      "INFO:tensorflow:Summary name histogram of b_fc is illegal; using histogram_of_b_fc instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('fully_conneted'):\n",
    "    W_fc = weight([7*7*C2, C3], name='weights')\n",
    "    b_fc = bias([C3], name='bias')\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1,7*7*C2])\n",
    "    h_fc = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc) + b_fc)\n",
    "    tf.summary.histogram('hsitogram of W_fc', W_fc)\n",
    "    tf.summary.histogram('histogram of b_fc', b_fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('dropout'):\n",
    "    p_keep = tf.placeholder(tf.float32)\n",
    "    h_fc_drop = tf.nn.dropout(h_fc, p_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Summary name histogram of W_out is illegal; using histogram_of_W_out instead.\n",
      "INFO:tensorflow:Summary name histogram of b_out is illegal; using histogram_of_b_out instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('output_layer'):\n",
    "    W_out = weight([C3,10], name='weights')\n",
    "    b_out = bias([10], name='bias')\n",
    "    y_pred = tf.matmul(h_fc_drop, W_out) + b_out\n",
    "    tf.summary.histogram('histogram of W_out', W_out)\n",
    "    tf.summary.histogram('histogram of b_out', b_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-4d19fb2fc996>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "INFO:tensorflow:Summary name loss of model is illegal; using loss_of_model instead.\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_gt, logits=y_pred))\n",
    "    tf.summary.scalar('loss of model', cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer(1e-4)\n",
    "    train_step = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('accuracy'):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_gt,1), tf.argmax(y_pred,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20000\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0, train accuracy 0.062500, test accuracy 0.050100\n",
      "iter 100, train accuracy 0.875000, test accuracy 0.878100\n",
      "iter 200, train accuracy 0.906250, test accuracy 0.915700\n",
      "iter 300, train accuracy 0.937500, test accuracy 0.933700\n",
      "iter 400, train accuracy 0.968750, test accuracy 0.940200\n",
      "iter 500, train accuracy 0.953125, test accuracy 0.950300\n",
      "iter 600, train accuracy 0.906250, test accuracy 0.954700\n",
      "iter 700, train accuracy 0.953125, test accuracy 0.959000\n",
      "iter 800, train accuracy 1.000000, test accuracy 0.962500\n",
      "iter 900, train accuracy 0.953125, test accuracy 0.964100\n",
      "iter 1000, train accuracy 0.953125, test accuracy 0.964800\n",
      "iter 1100, train accuracy 0.984375, test accuracy 0.968000\n",
      "iter 1200, train accuracy 1.000000, test accuracy 0.970100\n",
      "iter 1300, train accuracy 0.968750, test accuracy 0.973000\n",
      "iter 1400, train accuracy 0.984375, test accuracy 0.973200\n",
      "iter 1500, train accuracy 0.953125, test accuracy 0.972500\n",
      "iter 1600, train accuracy 1.000000, test accuracy 0.975100\n",
      "iter 1700, train accuracy 0.968750, test accuracy 0.973800\n",
      "iter 1800, train accuracy 1.000000, test accuracy 0.976600\n",
      "iter 1900, train accuracy 0.984375, test accuracy 0.975900\n",
      "iter 2000, train accuracy 0.984375, test accuracy 0.977600\n",
      "iter 2100, train accuracy 0.984375, test accuracy 0.979800\n",
      "iter 2200, train accuracy 0.984375, test accuracy 0.979200\n",
      "iter 2300, train accuracy 0.984375, test accuracy 0.980100\n",
      "iter 2400, train accuracy 0.984375, test accuracy 0.981000\n",
      "iter 2500, train accuracy 0.984375, test accuracy 0.981500\n",
      "iter 2600, train accuracy 0.984375, test accuracy 0.980700\n",
      "iter 2700, train accuracy 1.000000, test accuracy 0.983200\n",
      "iter 2800, train accuracy 0.984375, test accuracy 0.981300\n",
      "iter 2900, train accuracy 1.000000, test accuracy 0.983200\n",
      "iter 3000, train accuracy 0.968750, test accuracy 0.982200\n",
      "iter 3100, train accuracy 0.984375, test accuracy 0.982300\n",
      "iter 3200, train accuracy 0.984375, test accuracy 0.983900\n",
      "iter 3300, train accuracy 0.984375, test accuracy 0.983400\n",
      "iter 3400, train accuracy 0.984375, test accuracy 0.983300\n",
      "iter 3500, train accuracy 1.000000, test accuracy 0.985000\n",
      "iter 3600, train accuracy 0.953125, test accuracy 0.985100\n",
      "iter 3700, train accuracy 0.953125, test accuracy 0.985400\n",
      "iter 3800, train accuracy 0.984375, test accuracy 0.985800\n",
      "iter 3900, train accuracy 1.000000, test accuracy 0.984900\n",
      "iter 4000, train accuracy 0.968750, test accuracy 0.985400\n",
      "iter 4100, train accuracy 1.000000, test accuracy 0.985600\n",
      "iter 4200, train accuracy 1.000000, test accuracy 0.985900\n",
      "iter 4300, train accuracy 0.953125, test accuracy 0.986100\n",
      "iter 4400, train accuracy 1.000000, test accuracy 0.988100\n",
      "iter 4500, train accuracy 0.984375, test accuracy 0.984800\n",
      "iter 4600, train accuracy 1.000000, test accuracy 0.986000\n",
      "iter 4700, train accuracy 1.000000, test accuracy 0.987800\n",
      "iter 4800, train accuracy 1.000000, test accuracy 0.986200\n",
      "iter 4900, train accuracy 1.000000, test accuracy 0.987600\n",
      "iter 5000, train accuracy 0.968750, test accuracy 0.987400\n",
      "iter 5100, train accuracy 1.000000, test accuracy 0.988800\n",
      "iter 5200, train accuracy 1.000000, test accuracy 0.988700\n",
      "iter 5300, train accuracy 0.984375, test accuracy 0.988800\n",
      "iter 5400, train accuracy 1.000000, test accuracy 0.987600\n",
      "iter 5500, train accuracy 0.984375, test accuracy 0.988000\n",
      "iter 5600, train accuracy 0.984375, test accuracy 0.987900\n",
      "iter 5700, train accuracy 1.000000, test accuracy 0.988000\n",
      "iter 5800, train accuracy 1.000000, test accuracy 0.987900\n",
      "iter 5900, train accuracy 1.000000, test accuracy 0.989200\n",
      "iter 6000, train accuracy 1.000000, test accuracy 0.989600\n",
      "iter 6100, train accuracy 1.000000, test accuracy 0.989500\n",
      "iter 6200, train accuracy 1.000000, test accuracy 0.989300\n",
      "iter 6300, train accuracy 0.984375, test accuracy 0.989200\n",
      "iter 6400, train accuracy 1.000000, test accuracy 0.989700\n",
      "iter 6500, train accuracy 0.984375, test accuracy 0.989500\n",
      "iter 6600, train accuracy 1.000000, test accuracy 0.990900\n",
      "iter 6700, train accuracy 0.984375, test accuracy 0.989800\n",
      "iter 6800, train accuracy 0.968750, test accuracy 0.990200\n",
      "iter 6900, train accuracy 1.000000, test accuracy 0.989500\n",
      "iter 7000, train accuracy 1.000000, test accuracy 0.989700\n",
      "iter 7100, train accuracy 1.000000, test accuracy 0.990300\n",
      "iter 7200, train accuracy 1.000000, test accuracy 0.990600\n",
      "iter 7300, train accuracy 0.984375, test accuracy 0.989500\n",
      "iter 7400, train accuracy 1.000000, test accuracy 0.990800\n",
      "iter 7500, train accuracy 1.000000, test accuracy 0.990400\n",
      "iter 7600, train accuracy 0.984375, test accuracy 0.990300\n",
      "iter 7700, train accuracy 0.984375, test accuracy 0.989800\n",
      "iter 7800, train accuracy 1.000000, test accuracy 0.989900\n",
      "iter 7900, train accuracy 1.000000, test accuracy 0.990400\n",
      "iter 8000, train accuracy 1.000000, test accuracy 0.991200\n",
      "iter 8100, train accuracy 1.000000, test accuracy 0.989900\n",
      "iter 8200, train accuracy 1.000000, test accuracy 0.991000\n",
      "iter 8300, train accuracy 1.000000, test accuracy 0.988500\n",
      "iter 8400, train accuracy 1.000000, test accuracy 0.989700\n",
      "iter 8500, train accuracy 1.000000, test accuracy 0.991000\n",
      "iter 8600, train accuracy 1.000000, test accuracy 0.990500\n",
      "iter 8700, train accuracy 1.000000, test accuracy 0.989800\n",
      "iter 8800, train accuracy 1.000000, test accuracy 0.991200\n",
      "iter 8900, train accuracy 1.000000, test accuracy 0.989800\n",
      "iter 9000, train accuracy 1.000000, test accuracy 0.991300\n",
      "iter 9100, train accuracy 1.000000, test accuracy 0.991100\n",
      "iter 9200, train accuracy 1.000000, test accuracy 0.991100\n",
      "iter 9300, train accuracy 1.000000, test accuracy 0.990700\n",
      "iter 9400, train accuracy 1.000000, test accuracy 0.990700\n",
      "iter 9500, train accuracy 1.000000, test accuracy 0.989600\n",
      "iter 9600, train accuracy 0.984375, test accuracy 0.991400\n",
      "iter 9700, train accuracy 0.984375, test accuracy 0.990900\n",
      "iter 9800, train accuracy 1.000000, test accuracy 0.990200\n",
      "iter 9900, train accuracy 1.000000, test accuracy 0.991000\n",
      "iter 10000, train accuracy 1.000000, test accuracy 0.991100\n",
      "iter 10100, train accuracy 1.000000, test accuracy 0.989800\n",
      "iter 10200, train accuracy 1.000000, test accuracy 0.991600\n",
      "iter 10300, train accuracy 1.000000, test accuracy 0.991200\n",
      "iter 10400, train accuracy 1.000000, test accuracy 0.990300\n",
      "iter 10500, train accuracy 1.000000, test accuracy 0.991700\n",
      "iter 10600, train accuracy 1.000000, test accuracy 0.992300\n",
      "iter 10700, train accuracy 1.000000, test accuracy 0.991500\n",
      "iter 10800, train accuracy 1.000000, test accuracy 0.990400\n",
      "iter 10900, train accuracy 1.000000, test accuracy 0.990600\n",
      "iter 11000, train accuracy 1.000000, test accuracy 0.991300\n",
      "iter 11100, train accuracy 1.000000, test accuracy 0.992700\n",
      "iter 11200, train accuracy 0.984375, test accuracy 0.992600\n",
      "iter 11300, train accuracy 1.000000, test accuracy 0.991700\n",
      "iter 11400, train accuracy 1.000000, test accuracy 0.992400\n",
      "iter 11500, train accuracy 1.000000, test accuracy 0.991700\n",
      "iter 11600, train accuracy 0.984375, test accuracy 0.991200\n",
      "iter 11700, train accuracy 1.000000, test accuracy 0.992000\n",
      "iter 11800, train accuracy 1.000000, test accuracy 0.991200\n",
      "iter 11900, train accuracy 0.984375, test accuracy 0.992300\n",
      "iter 12000, train accuracy 1.000000, test accuracy 0.992300\n",
      "iter 12100, train accuracy 1.000000, test accuracy 0.992100\n",
      "iter 12200, train accuracy 1.000000, test accuracy 0.991900\n",
      "iter 12300, train accuracy 1.000000, test accuracy 0.992600\n",
      "iter 12400, train accuracy 0.984375, test accuracy 0.992500\n",
      "iter 12500, train accuracy 1.000000, test accuracy 0.993200\n",
      "iter 12600, train accuracy 1.000000, test accuracy 0.992600\n",
      "iter 12700, train accuracy 1.000000, test accuracy 0.991700\n",
      "iter 12800, train accuracy 1.000000, test accuracy 0.992500\n",
      "iter 12900, train accuracy 1.000000, test accuracy 0.991700\n",
      "iter 13000, train accuracy 1.000000, test accuracy 0.992600\n",
      "iter 13100, train accuracy 1.000000, test accuracy 0.992200\n",
      "iter 13200, train accuracy 1.000000, test accuracy 0.992800\n",
      "iter 13300, train accuracy 1.000000, test accuracy 0.992500\n",
      "iter 13400, train accuracy 1.000000, test accuracy 0.992200\n",
      "iter 13500, train accuracy 1.000000, test accuracy 0.991600\n",
      "iter 13600, train accuracy 1.000000, test accuracy 0.992000\n",
      "iter 13700, train accuracy 1.000000, test accuracy 0.992100\n",
      "iter 13800, train accuracy 1.000000, test accuracy 0.992700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 13900, train accuracy 1.000000, test accuracy 0.991800\n",
      "iter 14000, train accuracy 1.000000, test accuracy 0.992300\n",
      "iter 14100, train accuracy 1.000000, test accuracy 0.992600\n",
      "iter 14200, train accuracy 1.000000, test accuracy 0.991900\n",
      "iter 14300, train accuracy 1.000000, test accuracy 0.991500\n",
      "iter 14400, train accuracy 1.000000, test accuracy 0.991900\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    summary = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter('MNIST_logs/train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter('MNIST_logs/test', sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for iter in range(epochs):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_step, feed_dict={x:batch_x, y_gt:batch_y, p_keep:0.5})\n",
    "        if iter % 100 == 0:\n",
    "            train_loss = sess.run(cross_entropy, feed_dict={x:batch_x, y_gt:batch_y, p_keep:1.0})\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={x:batch_x, y_gt:batch_y, p_keep:1.0})\n",
    "            \n",
    "            test_accuracy = sess.run(accuracy, feed_dict={x:mnist.test.images, y_gt:mnist.test.labels, p_keep:1.0})\n",
    "            print('iter %d, train accuracy %f, test accuracy %f' % (iter, train_accuracy, test_accuracy))\n",
    "            \n",
    "            summary_train = sess.run(summary,{x:batch_x,y_gt:batch_y,p_keep:1.0})\n",
    "            summary_test = sess.run(summary,{x:mnist.test.images,y_gt:mnist.test.labels,p_keep:1.0})\n",
    "            train_writer.add_summary(summary_train, iter)\n",
    "            test_writer.add_summary(summary_test, iter)\n",
    "            train_writer.flush()\n",
    "            test_writer.flush()\n",
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard --logdir MNIST_logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
