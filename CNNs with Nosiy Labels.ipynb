{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://github.com/adeshpande3/Tensorflow-Programs-and-Tutorials/blob/master/CNNs%20with%20Noisy%20Labels.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is to test out whether a CNN that is trained on noisy labels is still able to achieve good accuracy.\n",
    "______\n",
    "However, my result is not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quansun/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-a5f771ab0f2b>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/quansun/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/quansun/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./Basic/mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/quansun/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./Basic/mnist/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/quansun/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting ./Basic/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./Basic/mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/quansun/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "mnist = input_data.read_data_sets('./Basic/mnist', one_hot=True)\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "x = tf.placeholder(tf.float32,shape=[None,784])\n",
    "y_ = tf.placeholder(tf.float32,shape=[None,10])\n",
    "x_image = tf.reshape(x,[-1,28,28,1])\n",
    "\n",
    "# first conv layer\n",
    "W_conv1 = tf.Variable(tf.truncated_normal([5,5,1,32],stddev=0.1))\n",
    "b_conv1 = tf.Variable(tf.constant(0.1,shape=[32]))\n",
    "h_conv1 = tf.nn.conv2d(x_image,W_conv1,strides=[1,1,1,1],padding='SAME') + b_conv1\n",
    "h_conv1 = tf.nn.relu(h_conv1)\n",
    "h_pool1 = tf.nn.max_pool(h_conv1,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "# second conv layer\n",
    "W_conv2 = tf.Variable(tf.truncated_normal([5,5,32,64],stddev=0.1))\n",
    "b_conv2 = tf.Variable(tf.constant(0.1,shape=[64]))\n",
    "h_conv2 = tf.nn.conv2d(h_pool1,W_conv2,strides=[1,1,1,1],padding='SAME')+b_conv2\n",
    "h_conv2 = tf.nn.relu(h_conv2)\n",
    "h_pool2 = tf.nn.max_pool(h_conv2,ksize=[1,2,2,1],strides=[1,2,2,1],padding='SAME')\n",
    "\n",
    "# first fully commected layer\n",
    "W_fc1 = tf.Variable(tf.truncated_normal([7*7*64,1024],stddev=0.1))\n",
    "b_fc1 = tf.Variable(tf.constant(0.1,shape=[1024]))\n",
    "h_pool2_flat = tf.reshape(h_pool2,[-1,7*7*64])\n",
    "h_fc1 = tf.matmul(h_pool2_flat, W_fc1) + b_fc1\n",
    "h_fc1 = tf.nn.relu(h_fc1)\n",
    "\n",
    "# dropout layer\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1,keep_prob)\n",
    "\n",
    "# second fully connected layer\n",
    "W_fc2 = tf.Variable(tf.truncated_normal([1024,10],stddev=0.1))\n",
    "b_fc2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "y = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "# loss\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y,labels=y_))\n",
    "correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "train_step = optimizer.minimize(loss)\n",
    "\n",
    "# Session\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nosiy labels settings\n",
    "changeLabelProbability = 0.5\n",
    "\n",
    "tf.summary.scalar('Loss', loss)\n",
    "tf.summary.scalar('Accuracy', accuracy)\n",
    "merged = tf.summary.merge_all()\n",
    "logdir = 'tensorboard/' + 'ChangeLabelProbability:' + str(changeLabelProbability) + '/'\n",
    "writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.09375\n",
      "step 1000, training accuracy 0.140625\n",
      "step 2000, training accuracy 0.109375\n",
      "step 3000, training accuracy 0.234375\n",
      "step 4000, training accuracy 0.203125\n",
      "step 5000, training accuracy 0.234375\n",
      "step 6000, training accuracy 0.28125\n",
      "step 7000, training accuracy 0.25\n",
      "step 8000, training accuracy 0.203125\n",
      "step 9000, training accuracy 0.265625\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    x_batch, y_batch = mnist.train.next_batch(batch_size)\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        summary = sess.run(merged, feed_dict={x:x_batch, y_:y_batch, keep_prob:1.0})\n",
    "        writer.add_summary(summary, epoch)\n",
    "        \n",
    "    if epoch % 1000 == 0:\n",
    "        train_accuracy = accuracy.eval(session=sess, feed_dict={x:x_batch,y_:y_batch,keep_prob:1.0})\n",
    "        \n",
    "        print('step %d, training accuracy %g' % (epoch, train_accuracy))\n",
    "        \n",
    "        # noisy labels\n",
    "        if (random.random() < changeLabelProbability):\n",
    "            for batch in range(batch_size):\n",
    "                originalTrainingLabel = np.argmax(y_batch[batch])\n",
    "                validOtherChoices = list(range(0,originalTrainingLabel)) + list(range(originalTrainingLabel+1,10))\n",
    "                newTrainingLabel = random.choice(validOtherChoices)\n",
    "                y_batch[batch] = np.zeros(10)\n",
    "                y_batch[batch][newTrainingLabel] = 1\n",
    "                \n",
    "        train_step.run(session=sess,feed_dict={x:x_batch,y_:y_batch,keep_prob:0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, testing accuracy 0.265625\n",
      "step 1, testing accuracy 0.25\n",
      "step 2, testing accuracy 0.25\n",
      "step 3, testing accuracy 0.25\n",
      "step 4, testing accuracy 0.171875\n",
      "step 5, testing accuracy 0.296875\n",
      "step 6, testing accuracy 0.25\n",
      "step 7, testing accuracy 0.28125\n",
      "step 8, testing accuracy 0.25\n",
      "step 9, testing accuracy 0.265625\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x_test_batch, y_test_batch = mnist.test.next_batch(batch_size)\n",
    "    test_accuracy = sess.run(accuracy,feed_dict={x:x_test_batch,y_:y_test_batch,keep_prob:1.0})\n",
    "    print('step %d, testing accuracy %g' % (i,test_accuracy))  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
